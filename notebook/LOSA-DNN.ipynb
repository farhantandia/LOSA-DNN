{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "import tensorflow as tf\r\n",
    "import os\r\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \r\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\"\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
    "from tensorflow.keras import optimizers, regularizers\r\n",
    "from tensorflow.keras.models import Sequential, Model ,load_model\r\n",
    "from tensorflow.keras.layers import *\r\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\r\n",
    "from tensorflow import keras\r\n",
    "\r\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3\r\n",
    "import efficientnet.tfkeras as efn \r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn import metrics \r\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\r\n",
    "from sklearn.metrics import multilabel_confusion_matrix\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "\r\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedKFold, cross_validate\r\n",
    "\r\n",
    "import tensorflow.keras.backend as K\r\n",
    "import keras_video.utils\r\n",
    "from keras_video import VideoFrameGenerator,SlidingFrameGenerator\r\n",
    "import glob\r\n",
    "import tensorflow_addons as tfa\r\n",
    "import pandas as pd\r\n",
    "from PIL import ImageOps"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.test.is_gpu_available()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = 'UCF101' #'UCF101' or 'HMDB51' dataset folder name\r\n",
    "with open(dataset+'/classInd.txt') as f:\r\n",
    "# with open('classInd.txt') as f:\r\n",
    "    classes = f.readlines()\r\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\r\n",
    "classes = [x.strip() for x in classes]\r\n",
    "classes.sort()\r\n",
    "len(classes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create video frame generator\r\n",
    "def frame_generator(video_path,classes,NBFRAME,BS,CHANNELS,SIZE,sliding_time):\r\n",
    "    data_aug = ImageDataGenerator(\r\n",
    "#     zoom_range=[0.8, 1.2],\r\n",
    "#       rescale=1./255,\r\n",
    "#     horizontal_flip=True,\r\n",
    "#     preprocessing_function=get_random_eraser(v_l=0, v_h=255)\r\n",
    "#     rotation_range=8,\r\n",
    "#     width_shift_range=.2,\r\n",
    "#     height_shift_range=.2\r\n",
    ")\r\n",
    "#     training_data = VideoFrameGenerator(\r\n",
    "#         classes = classes, \r\n",
    "#         glob_pattern = video_path,\r\n",
    "#         nb_frames = NBFRAME,\r\n",
    "#         shuffle = True,\r\n",
    "#         batch_size=BS,\r\n",
    "#         target_shape=SIZE,\r\n",
    "#         nb_channel=CHANNELS,\r\n",
    "#         transformation=data_aug,\r\n",
    "#         use_frame_cache=False)\r\n",
    "    \r\n",
    "    training_data = SlidingFrameGenerator(\r\n",
    "        sequence_time=sliding_time,\r\n",
    "        classes = classes, \r\n",
    "        glob_pattern = video_path,\r\n",
    "        nb_frames = NBFRAME,\r\n",
    "        shuffle = True,\r\n",
    "        batch_size=BS,\r\n",
    "        target_shape=SIZE,\r\n",
    "        nb_channel=CHANNELS,\r\n",
    "        transformation=data_aug,\r\n",
    "        use_frame_cache=False)\r\n",
    "    return training_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def spatial_attention(input_feature):\r\n",
    "    #kernel_size = 7\r\n",
    "    kernel_size = 3\r\n",
    "    \r\n",
    "    if K.image_data_format() == \"channels_first\":\r\n",
    "        channel = input_feature.shape[1]\r\n",
    "        cbam_feature = Permute((2,3,1))(input_feature)\r\n",
    "    else:\r\n",
    "        channel = input_feature.shape[-1]\r\n",
    "        cbam_feature = input_feature\r\n",
    "\r\n",
    "    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\r\n",
    "    assert avg_pool.shape[-1] == 1\r\n",
    "    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\r\n",
    "    assert max_pool.shape[-1] == 1\r\n",
    "    concat = Concatenate(axis=3)([avg_pool, max_pool])\r\n",
    "    assert concat.shape[-1] == 2\r\n",
    "    cbam_feature = Conv2D(filters = 1,\r\n",
    "                    kernel_size=kernel_size,\r\n",
    "                    strides=1,\r\n",
    "                    padding='same',\r\n",
    "                    activation='sigmoid',\r\n",
    "                    kernel_initializer='he_normal',\r\n",
    "                    use_bias=False)(concat)\t\r\n",
    "    assert cbam_feature.shape[-1] == 1\r\n",
    "\r\n",
    "    if K.image_data_format() == \"channels_first\":\r\n",
    "        cbam_feature = Permute((3, 1, 2))(cbam_feature)\r\n",
    "\r\n",
    "    return multiply([input_feature, cbam_feature])\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Adaptive LR Scheduler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class LossLearningRateScheduler(tf.keras.callbacks.History):\r\n",
    "    \"\"\"\r\n",
    "    A learning rate scheduler that relies on changes in loss function\r\n",
    "    value to dictate whether learning rate is decayed or not.\r\n",
    "    LossLearningRateScheduler has the following properties:\r\n",
    "    base_lr: the starting learning rate\r\n",
    "    lookback_epochs: the number of epochs in the past to compare with the loss function at the current epoch to determine if progress is being made.\r\n",
    "    decay_threshold / decay_multiple: if loss function has not improved by a factor of decay_threshold * lookback_epochs, then decay_multiple will be applied to the learning rate.\r\n",
    "    spike_epochs: list of the epoch numbers where you want to spike the learning rate.\r\n",
    "    spike_multiple: the multiple applied to the current learning rate for a spike.\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    def __init__(self, base_lr, lookback_epochs, spike_epochs = None, spike_multiple = 10, decay_threshold = 0.002, decay_multiple = 0.50, loss_type = 'val_loss'):\r\n",
    "\r\n",
    "        super(LossLearningRateScheduler, self).__init__()\r\n",
    "\r\n",
    "        self.base_lr = base_lr\r\n",
    "        self.lookback_epochs = lookback_epochs\r\n",
    "        self.spike_epochs = spike_epochs\r\n",
    "        self.spike_multiple = spike_multiple\r\n",
    "        self.decay_threshold = decay_threshold\r\n",
    "        self.decay_multiple = decay_multiple\r\n",
    "        self.loss_type = loss_type\r\n",
    "\r\n",
    "\r\n",
    "    def on_epoch_begin(self, epoch, logs=None):\r\n",
    "\r\n",
    "        if len(self.epoch) > self.lookback_epochs:\r\n",
    "\r\n",
    "            current_lr = tf.keras.backend.get_value(self.model.optimizer.lr)\r\n",
    "\r\n",
    "            target_loss = self.history[self.loss_type] \r\n",
    "\r\n",
    "            loss_diff =  target_loss[-int(self.lookback_epochs)] - target_loss[-1]\r\n",
    "\r\n",
    "            if loss_diff <= np.abs(target_loss[-1]) * (self.decay_threshold * self.lookback_epochs):\r\n",
    "\r\n",
    "                print(' '.join(('Changing learning rate from', str(current_lr), 'to', str(current_lr * self.decay_multiple))))\r\n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, current_lr * self.decay_multiple)\r\n",
    "                current_lr = current_lr * self.decay_multiple\r\n",
    "\r\n",
    "            else:\r\n",
    "\r\n",
    "                print(' '.join(('Learning rate:', str(current_lr))))\r\n",
    "\r\n",
    "            if self.spike_epochs is not None and len(self.epoch) in self.spike_epochs:\r\n",
    "                print(' '.join(('Spiking learning rate from', str(current_lr), 'to', str(current_lr * self.spike_multiple))))\r\n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, current_lr * self.spike_multiple)\r\n",
    "\r\n",
    "        else:\r\n",
    "\r\n",
    "            print(' '.join(('Setting learning rate to', str(self.base_lr))))\r\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, self.base_lr)\r\n",
    "\r\n",
    "\r\n",
    "        return tf.keras.backend.get_value(self.model.optimizer.lr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backbone Layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# eff_model = efn.EfficientNetB3(weights='imagenet', include_top = False)\r\n",
    "# model_backbone = Model(eff_model.input,eff_model.output)\r\n",
    "# pd.set_option('max_colwidth', -1)\r\n",
    "# layers = [(layer, layer.name, layer.trainable) for layer in model_backbone.layers]\r\n",
    "# dt = pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])\r\n",
    "# dt.to_csv(\"layers.csv\", index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LIGHTWEIGHT ONE-IN-TWO STREAM ATTENTION-BASED DNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras_self_attention import SeqSelfAttention\r\n",
    "def fusion_attention_lstm(image_input_shape,n_class,height,width):\r\n",
    "    y = Input(shape=(n_class,))\r\n",
    "    input_image = Input(shape=image_input_shape)\r\n",
    "    eff_model=efn.EfficientNetB3(input_shape=(height, width, 3),\r\n",
    "                                 include_top=False,\r\n",
    "                                 weights='noisy-student')\r\n",
    "    model_backbone = Model(eff_model.input,eff_model.get_layer('block7a_project_bn').output)\r\n",
    "    timeDistributed_layer = tf.keras.layers.TimeDistributed(model_backbone)(input_image)\r\n",
    "    print(\"TimeDistributed\", timeDistributed_layer.shape)\r\n",
    "    \r\n",
    "    '''Temporal'''\r\n",
    "    t = tf.keras.layers.TimeDistributed(GlobalAveragePooling2D())(timeDistributed_layer)\r\n",
    "    t = LSTM(256, return_sequences=True, input_shape=(t.shape[1],t.shape[2]), name=\"lstm_layer_in\")(t)\r\n",
    "    t = SeqSelfAttention(attention_activation='sigmoid')(t)\r\n",
    "    avg_pool = GlobalAveragePooling1D()(t)\r\n",
    "    max_pool = GlobalMaxPooling1D()(t)\r\n",
    "    t = concatenate([avg_pool, max_pool])\r\n",
    "    \r\n",
    "    t = Dropout(0.3)(t)\r\n",
    "    print(\"Temporal: \", t.shape)\r\n",
    "    \r\n",
    "    '''Spatial'''\r\n",
    "    s = tf.math.reduce_mean(timeDistributed_layer, axis=1)   \r\n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\r\n",
    "    s = spatial_attention(s)\r\n",
    "    s = SeparableConv2D(filters = 512, kernel_size = (3, 3), padding = 'same')(s)\r\n",
    "    s = spatial_attention(s)\r\n",
    "    s = BatchNormalization()(s)\r\n",
    "    a = GlobalAveragePooling2D()(s)\r\n",
    "    c = Dropout(0.3)(a)\r\n",
    "    print(\"Spatial: \", s.shape)\r\n",
    "    \r\n",
    "    \r\n",
    "    '''Fusion'''\r\n",
    "    f = tf.keras.layers.Concatenate()([c, t])\r\n",
    "    f = Dropout(0.3)(f)\r\n",
    "    print(\"Fusion: \", f.shape)\r\n",
    "    \r\n",
    "    return f,y,input_image\r\n",
    "\r\n",
    "def fc_action(x,n_class,y):\r\n",
    "    x = Dense(1024, name=\"fusion_dense1\")(x)\r\n",
    "    x = PReLU()(x)\r\n",
    "    x = BatchNormalization()(x)\r\n",
    "    x = Dropout(0.5)(x)\r\n",
    "    x = Dense(n_class, activation='softmax',name=\"action_output\")(x)\r\n",
    "    return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Initialization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lr_init = 1e-4\r\n",
    "def create_model_fusion(image_input_shape,n_class,height,width,lr_init):\r\n",
    "    model,y,input_image = fusion_attention_lstm(image_input_shape,n_class,height,width)\r\n",
    "    softmax_action = fc_action(model,n_class,y)\r\n",
    "    model = tf.keras.models.Model(inputs=input_image, outputs=softmax_action)\r\n",
    "    opt = tfa.optimizers.LazyAdam(lr=lr_init)\r\n",
    "#     model.load_weights(\"ucf_model/UCF_MTDNN_2.h5\")\r\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\r\n",
    "    return model\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Callback & Compile"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def scheduler(epoch, lr =lr_init):\r\n",
    "    if epoch <= 5:\r\n",
    "        return 0.000\r\n",
    "    if epoch > 5 and epoch <= 10:\r\n",
    "        return 0.00005\r\n",
    "    if epoch > 10 and epoch <= 20:\r\n",
    "        return 0.000005\r\n",
    "    if epoch > 20:\r\n",
    "        return 0.00001\r\n",
    "\r\n",
    "\r\n",
    "def run_model_generator(Model_input_size,img_height,img_width,data_train,data_test,epoch,n_split,lr_init):\r\n",
    "#     mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\", \"/gpu:2\"], cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\r\n",
    "    #print('Number of devices: {}'.format(strategy.numde_replicas_in_sync))\r\n",
    "\r\n",
    "    history_list = []\r\n",
    "    n_class = len(classes)\r\n",
    "#     with tf.device('/gpu:1'):\r\n",
    "#     with mirrored_strategy.scope():\r\n",
    "    model = create_model_fusion(Model_input_size,n_class,img_height, img_width,lr_init)\r\n",
    "    model.summary()\r\n",
    "\r\n",
    "    model_path = dataset+\"_model_\"+str(n_split)+\".h5\"\r\n",
    "    \r\n",
    "#     callback_step = tf.keras.callbacks.LearningRateScheduler(scheduler) \r\n",
    "    callback_adapt = LossLearningRateScheduler(base_lr=lr_init, lookback_epochs=3)\r\n",
    "\r\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path,\r\n",
    "                                 monitor='val_loss',\r\n",
    "                                 verbose=1,\r\n",
    "                                 save_best_only=True)\r\n",
    "    stop = EarlyStopping(monitor='val_loss', patience = 10,\r\n",
    "                          verbose=0, mode='auto', baseline=None, \r\n",
    "                          restore_best_weights=False)\r\n",
    "    callbacks = [checkpoint, stop,callback_adapt]\r\n",
    "    steps_per_epoch= (9537 * 0.7) // BS\r\n",
    "    eval_per_epoch= 100\r\n",
    "    history = model.fit_generator(data_train,\r\n",
    "                                  epochs=epoch, \r\n",
    "                                  shuffle=True, \r\n",
    "                                  steps_per_epoch=steps_per_epoch,\r\n",
    "                                  validation_data = data_test, \r\n",
    "                                  validation_steps=eval_per_epoch,\r\n",
    "                                  callbacks=callbacks)\r\n",
    "\r\n",
    "    history_list.append(np.max(model.history.history['val_accuracy']))\r\n",
    "    return history_list\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epoch= 200\r\n",
    "img_height, img_width = 299,299\r\n",
    "SIZE = (img_height, img_width)\r\n",
    "CHANNELS = 3\r\n",
    "NBFRAME = 5\r\n",
    "sliding_time = 4\r\n",
    "Model_input_size = (NBFRAME, img_height, img_width, CHANNELS)\r\n",
    "BS =4\r\n",
    "seq_len = NBFRAME\r\n",
    "stride = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split 1 Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"***Load split 1***\")\r\n",
    "train_files =dataset+'/train1/{classname}/*.avi'\r\n",
    "test_files =dataset+'/test1/{classname}/*.avi'\r\n",
    "\r\n",
    "train_data = frame_generator(train_files,classes,NBFRAME,BS,CHANNELS,SIZE,sliding_time)\r\n",
    "test_data = frame_generator(test_files,classes,NBFRAME,BS,CHANNELS,SIZE,sliding_time)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "\r\n",
    "split1_acc = run_model_generator(Model_input_size,img_height,img_width,train_data,test_data,epoch,1,lr_init)\r\n",
    "print(\"Split 1 Accuracy : \",split1_acc)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split 2 Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"***Load split 2***\")\r\n",
    "\r\n",
    "train_files =dataset+'/train2/{classname}/*.avi'\r\n",
    "test_files =dataset+'/test2/{classname}/*.avi'\r\n",
    "\r\n",
    "train_data = frame_generator(train_files,classes,NBFRAME,BS,CHANNELS,SIZE,sliding_time)\r\n",
    "test_data = frame_generator(test_files,classes,NBFRAME,BS,CHANNELS,SIZE,sliding_time)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time   \r\n",
    "split2_acc = run_model_generator(Model_input_size,img_height,img_width,train_data,test_data,epoch,2,lr_init)\r\n",
    "print(\"Split 2 Accuracy : \",split2_acc)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split 3 Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"***Load split 3***\")\r\n",
    "\r\n",
    "train_files =dataset+'/train3/{classname}/*.avi'\r\n",
    "test_files =dataset+'/test3/{classname}/*.avi'\r\n",
    "\r\n",
    "train_data = frame_generator(train_files,classes,NBFRAME,BS,CHANNELS,SIZE,sliding_time)\r\n",
    "test_data = frame_generator(test_files,classes,NBFRAME,BS,CHANNELS,SIZE,sliding_time)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\r\n",
    "split3_acc = run_model_generator(Model_input_size,img_height,img_width,train_data,test_data,epoch,3,lr_init)\r\n",
    "print(\"Split 3 Accuracy : \",split3_acc)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "(90.25+91.75+90)/3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 Split Accuracy (Mean)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Split 1 Accuracy : \",np.max(split1_acc))\r\n",
    "print(\"Split 2 Accuracy : \",np.max(split2_acc))\r\n",
    "print(\"Split 3 Accuracy : \",np.max(split3_acc))\r\n",
    "print(\"3 Split Accuracy (Mean): \", (np.max(split1_acc)+np.max(split2_acc)+np.max(split3_acc))/3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = create_model_fusion((5,299,299,3),128,101,299, 299,1e-4)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def frames_extraction(video_path, c, X, Y, Xf, Yf, img_width, img_height,sscnt,stride,seq_len, isTraining):\r\n",
    "    frames_list = []\r\n",
    "    flist = []\r\n",
    "     \r\n",
    "    vidObj = cv2.VideoCapture(video_path)\r\n",
    "    # Used as counter variable \r\n",
    "    count = 1\r\n",
    "    \r\n",
    "    tmp_frames = []\r\n",
    "    zoom_frames = []\r\n",
    "    \r\n",
    "    while 1:\r\n",
    "        success, image = vidObj.read()\r\n",
    "        if success:\r\n",
    "            count += 1\r\n",
    "            if count % stride == 0:\r\n",
    "                image = image.astype(np.float32)\r\n",
    "#                 image /= 255.0\r\n",
    "                image = cv2.resize(image, (img_width, img_height))\r\n",
    "#                 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
    "                tmp_frames.append(image)\r\n",
    "    \r\n",
    "                if isTraining:\r\n",
    "                    zoom_image = clipped_zoom(image, 1.2)\r\n",
    "                    zoom_frames.append(zoom_image)\r\n",
    "            \r\n",
    "            if len(tmp_frames) == seq_len:\r\n",
    "                sscnt += 1\r\n",
    "                X.append(tmp_frames)\r\n",
    "\r\n",
    "                y = [0]*len(classes)\r\n",
    "                y[classes.index(c)] = 1\r\n",
    "                Y.append(y)\r\n",
    "                \r\n",
    "                if isTraining:\r\n",
    "                    aug_frames = []\r\n",
    "                    for t in tmp_frames:\r\n",
    "                        aug_frames.append(cv2.flip(t, 1))\r\n",
    "                    X.append(aug_frames)\r\n",
    "                    Y.append(y)\r\n",
    "                    X.append(zoom_frames)\r\n",
    "                    Y.append(y)\r\n",
    "                \r\n",
    "                \r\n",
    "                tmp_frames = []\r\n",
    "                break\r\n",
    "                #tmp_flow_frames = []\r\n",
    "        else:\r\n",
    "            #print(\"Defected frame\")\r\n",
    "            break\r\n",
    "            \r\n",
    "    return X, Y, Xf, Yf, sscnt\r\n",
    " \r\n",
    "def create_data(input_dir,stride,seq_len,img_width, img_height, isTraining):\r\n",
    "    X = []\r\n",
    "    Y = []\r\n",
    "    Xf = []\r\n",
    "    Yf = []\r\n",
    "    Xt = []\r\n",
    "    Yt = []\r\n",
    "    sscnt = 0\r\n",
    "    for c in classes:\r\n",
    "        print(c)\r\n",
    "        if not (c in classes):\r\n",
    "            continue\r\n",
    "        files_list = os.listdir(os.path.join(input_dir, c))\r\n",
    "        sscnt = 0\r\n",
    "        for f in files_list:\r\n",
    "            X, Y, Xf, Yf, sscnt = frames_extraction(os.path.join(os.path.join(input_dir, c), f), c, X, Y, Xf, Yf, img_width, img_height,sscnt,stride,seq_len, isTraining)\r\n",
    "            \r\n",
    "    X = np.asarray(X)\r\n",
    "    Y = np.asarray(Y)\r\n",
    "    print(X.shape)\r\n",
    "    return X, Y\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "test3 = \"test1\"\n",
    "_X, _Y = create_data(test3,stride,seq_len, img_width,img_height, 0)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_X.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "x = np.expand_dims(_X[0], axis=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = create_model_fusion(_X[0].shape,128,101,img_height, img_width,lr_init)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%time\n",
    "z=model.predict(x)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}